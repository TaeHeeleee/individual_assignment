# 인공지능과 기계학습 11주차

# 데이터 확인하기 
import seaborn as sns
import pandas as pd
import numpy as np

sns.set(style = 'ticks', color_codes = True)
iris = sns.load_dataset('iris')
g = sns.pairplot(iris, hue = 'species', palette = 'husl') 

iris.info()
iris['species'].unique()

# 문자열로 된 이름에 번호를 붙이고 그 번호를 원-핫 형식으로 변환하기 
from sklearn.preprocessing import LabelEncoder

X = iris.iloc[:, 0:4].values
y = iris.iloc[: ,4].values 

encoder = LabelEncoder()
y1 = encoder.fit_transform(y)
Y = pd.get_dummies(y1).values 

print(Y)

# 훈련 데이터와 테스트 데이터 나누기 
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1) 

X_train.shape, X_test.shape, y_train.shape, y_test.shape

# 학습모델 만들기
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam 

model = Sequential()

model.add(Dense(64, input_shape = (4, ), activation = 'relu'))
model.add(Dense(64, activation = 'relu'))
model.add(Dense(3, activation = 'softmax'))

# 학습 모델 컴파일
model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])

model. summary()

# 학습
hist = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100)

# 학습결과 확인하기
import matplotlib.pyplot as plt

plt.figure(figsize = (12, 8))
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.legend(['loss', 'val_loss', 'accuracy', 'val_accuracy'])
plt.grid()
plt.show()
